{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "![Descripci√≥n de la imagen](https://drive.google.com/uc?export=download&id=1LNMJ1zjBZkWJeZwJO38EJzfOWBHt4u4q)\n",
        "\n",
        "\n",
        "## **Clase 4 - GraphRAG**\n",
        "\n"
      ],
      "metadata": {
        "id": "MVateEsQFXjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objetivos de hoy\n",
        "\n",
        "**Objetivo Alumno:** Entender las limitaciones del RAG basado en texto y aprender a construir una base de conocimiento en forma de grafo para permitir un razonamiento complejo.\n",
        "\n",
        "**Objetivo Proyecto:** Crear un Knowledge Graph inicial que modele las relaciones entre productos, proveedores y pedidos.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Material de Clase\n",
        "Repositorio de Github\n",
        "\n",
        "https://github.com/tribu-ia/don-confiado\n",
        "\n",
        "\n",
        "**Este mismo colab**\n",
        "\n",
        "[https://colab.research.google.com/drive/1c5H7VbJq47fAt_diSrkIFCP9bpTgtq8](https://colab.research.google.com/drive/1c5H7VbJq47fAt_diSrkIFCP9bpTgtq8)\n",
        "\n",
        "\n",
        "URL Corta del Colab: [https://tinyurl.com/waftn9z9](https://tinyurl.com/waftn9z9)\n",
        "\n",
        "\n",
        "**Colab Clase Anterior**:\n",
        "https://colab.research.google.com/drive/1T15cJEjegMskuDccZoYTDbYWMiO2x1dA\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "96M1ww3VrQyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **C√≥mo se correlacionan RAG y LLM?**\n",
        "\n",
        "\n",
        "En la clase pasada vimos como utilizar RAG para traer pedazos de texto (o alguna otra fuente de \"conocimiento\") desde una base de datos vectorial.\n",
        "\n",
        "\n",
        "¬øC√≥mo hacemos que ese texto o conocimiento sea usado por LLM para dar una respuesta?\n",
        "\n",
        "\n",
        "Recuerdan que hab√≠amos explicado que los LLM entre sus caracter√≠sticas ten√≠an la capacidad de **parafrasear** y **\"razonar\"**.\n",
        "\n",
        "Utilizaremos esa caracteristica para enriquecer el **Prompt** inyectando ese texto de RAG en cada llamado.\n",
        "\n",
        "![Imagen desde Drive](https://drive.google.com/uc?export=view&id=133_lipxQacOQrtF66KP0xL3wOJ2IqQJG)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K0u9hB4qwm3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesos Tradicional de RAG\n",
        "\n",
        "![Imagen desde Drive](https://drive.google.com/uc?export=view&id=1IkMx3iBMzSpHlbFcwoFNA0sGHwQcAiEB)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j8UxCrsZjhZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problemas del RAG Tradicional\n",
        "\n",
        "- Los chunks no guardan relaciones entre ellos\n",
        "- Con los chunks no se puede obtener una visi√≥n global\n",
        "- Los chunks traidos podr√≠an no traer la respuesta\n"
      ],
      "metadata": {
        "id": "wnrJx08n_ctM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C√≥mo lo soluciona GraphRAG\n",
        "\n",
        "GraphRAG (Graph-based Retrieval-Augmented Generation) introduce una capa de razonamiento estructurado mediante un grafo de conocimiento (Knowledge Graph), combinando lo mejor del RAG con lo mejor de la representaci√≥n simb√≥lica.\n",
        "\n",
        "1. **Estructura sem√°ntica expl√≠cita**\n",
        "\n",
        "Extrae entidades (nodos) y relaciones (aristas) del corpus.\n",
        "\n",
        "Cada nodo tiene embeddings y conexiones expl√≠citas.\n",
        "\n",
        "Esto permite b√∫squedas no solo por similitud, sino tambi√©n por estructura (qui√©n se relaciona con qui√©n y c√≥mo).\n",
        "\n",
        "2. **Recuperaci√≥n basada en contexto conectado**\n",
        "\n",
        "Cuando se hace una consulta, GraphRAG puede expandir el grafo localmente para incluir entidades relacionadas, mejorando la relevancia contextual.\n",
        "\n",
        "As√≠ evita perder informaci√≥n que estaba dispersa en diferentes chunks.\n",
        "\n",
        "3. **Razonamiento multihop**\n",
        "\n",
        "Puede seguir relaciones en varios pasos (por ejemplo: A ‚Üí B ‚Üí C) para responder preguntas complejas que implican inferencia.\n",
        "\n",
        "Esto es imposible para RAG tradicional sin cadenas de prompts complicadas.\n",
        "\n",
        "4. **Menor redundancia, mayor precisi√≥n**\n",
        "\n",
        "La b√∫squeda sobre el grafo prioriza nodos relevantes y sus relaciones, reduciendo la repetici√≥n de textos similares.\n",
        "\n",
        "5. **Mayor interpretabilidad**\n",
        "\n",
        "Las respuestas pueden venir acompa√±adas del subgrafo usado para inferir la respuesta, mostrando de manera transparente las conexiones que sustentan la generaci√≥n.\n",
        "\n",
        "6. **Mejor rendimiento en dominios especializados**\n",
        "\n",
        "Ideal para datos empresariales, cient√≠ficos o legales donde las relaciones (por ejemplo, entre proyectos, contratos, o mol√©culas) son m√°s importantes que el texto literal."
      ],
      "metadata": {
        "id": "z2jKAlypDkFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agenda\n",
        "* Setup y llaves\n",
        "* Crear un Grafo\n",
        "* neo4j\n",
        "* Grafo + RAG + LLM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FlCNfvDkou94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *NO MAS TEORIA. VAMOS AL CODIGO*"
      ],
      "metadata": {
        "id": "e9d--t5pkdJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Instalando dotenv\")\n",
        "!pip install --quiet python-dotenv\n",
        "\n",
        "print(\"Instalando openai\")\n",
        "!pip install --quiet openai\n",
        "\n",
        "#print(\"Instalando genai\")\n",
        "#!pip install --quiet google-genai\n",
        "print(\"Instalando langchain langchain_google_genai langchain_openai langchain-neo4j langchain-experimental neo4j\")\n",
        "!pip install --quiet langchain langchain_google_genai langchain_openai langchain-neo4j langchain-experimental neo4j\n",
        "print(\"INSTALO DE TODO. Langchain Langchain experimental neo4j Gemini\")"
      ],
      "metadata": {
        "id": "FgpTv71P4DFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargamos las llaves üîë\n",
        "\n",
        "\n",
        "Ahora vamos a poner las llaves o (API_KEYS) de cada plataforma\n",
        "\n",
        "\n",
        "Recuerden crear los API KEYS de Google Gemini y OpenAI\n",
        "\n",
        "Google Gemini:  https://aistudio.google.com/api-keys\n",
        "\n",
        "OpenAI: https://platform.openai.com/api-keys\n",
        "\n",
        "\n",
        "Te las pedir√° o las puedes guardar para usos futuros.\n",
        "\n",
        "![image.png](https://drive.google.com/uc?export=download&id=1D3_pfko0lAequCnGSqfQLM-q24KA2LAj)\n"
      ],
      "metadata": {
        "id": "dlV-YrCQ7YDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "def assign_key(userdata,key_name:str, input_message:str, hint:str = None):\n",
        "  try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "  except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "  if IN_COLAB:\n",
        "    try:\n",
        "      key = userdata.get(key_name)\n",
        "      if key:\n",
        "        os.environ[key_name] = key\n",
        "        return os.environ[key_name]\n",
        "    except:\n",
        "      return os.environ[key_name]\n",
        "\n",
        "  if hint:\n",
        "    print(hint)\n",
        "  key = input(input_message)\n",
        "  os.environ[key_name] = key\n",
        "  return os.environ[key_name]\n",
        "\n",
        "\n",
        "\n",
        "gemini_api_key = assign_key(userdata, \"GEMINI_API_KEY\", \"Por favor, ingrese su API KEY de Gemini: \",\"Para obtener Gemini API Key https://aistudio.google.com/\")\n",
        "openai_api_key = assign_key(userdata, \"OPENAI_API_KEY\", \"Por favor, ingrese su API KEY de OPENAI: \" )\n",
        "NEO4J_URI = assign_key(userdata, \"NEO4J_URI\", \"Por favor, ingrese su URI de NEO4J: \" )\n",
        "NEO4J_USERNAME  = assign_key(userdata, \"NEO4J_USERNAME\", \"Por favor, ingrese su USERNAME de NEO4J: \" )\n",
        "NEO4J_PASSWORD  = assign_key(userdata, \"NEO4J_PASSWORD\", \"Por favor, ingrese su PASSWORD de NEO4J: \")\n",
        "NEO4J_DATABASE = assign_key(userdata, \"NEO4J_DATABASE\", \"Por favor, ingrese su DATABASE de NEO4J: \")\n",
        "\n",
        "\n",
        "print(\"Ya cargaste las llaves en las variables de entorno\")\n",
        "print(\"Puedes pasar a probar los APIs\")\n"
      ],
      "metadata": {
        "id": "OOikxQ4B-DGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Definimos algunas funciones √∫tiles para procesar archivos\n",
        "\n",
        "\n",
        "Como necesitamos procesar archivos vamos a crear unas funciones que nos ayudar√°n a descargarlas desde Internet y extraer sus bytes"
      ],
      "metadata": {
        "id": "ye_LtdTYCkSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "\n",
        "# Crearemos algunas funciones √∫tiles para manipular las im√°genes.\n",
        "\n",
        "\n",
        "# Necesitamos cargar los bytes de una im√°gen en un archivo.\n",
        "def load_image_bytes(path: str) -> bytes:\n",
        "    with open(path, \"rb\") as f:\n",
        "        return f.read()\n",
        "\n",
        "\n",
        "#Descargamos la imagen y la guardamos localmente\n",
        "def descargar_archivo(url: str, destino: str):\n",
        "    \"\"\"\n",
        "    Descarga un archivo desde una URL (por ejemplo, de Google Drive o Imgur)\n",
        "    y la guarda en la ruta especificada.\n",
        "\n",
        "    Par√°metros:\n",
        "        url (str): URL directa o de descarga del archivo.\n",
        "        destino (str): Ruta completa donde guardar el archivo, incluyendo el nombre del archivo.\n",
        "    \"\"\"\n",
        "    print(f\"üì• Descargando archivo desde: {url}\")\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(destino, \"wb\") as f:\n",
        "            for chunk in response.iter_content(1024):\n",
        "                f.write(chunk)\n",
        "        print(f\"‚úÖ Archivo descargado correctamente en: {destino}\")\n",
        "    else:\n",
        "        raise Exception(f\"‚ùå Error al descargar el archivo: {response.status_code}\")\n",
        "\n",
        "    # Verificar que el archivo existe y tiene contenido\n",
        "    if not os.path.exists(destino) or os.path.getsize(destino) == 0:\n",
        "        raise FileNotFoundError(\"‚ùå No se encontr√≥ el archivo o est√° vacio\")\n",
        "    else:\n",
        "        print(f\"üìè Tama√±o del archivo: {os.path.getsize(destino)} bytes\")\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# descargar archivo(\"https://drive.google.com/uc?export=download&id=1PMXWYR_hekobCV0jSrFEz5TpIjriU6jM\", \"/content/imagen_imgur.png\")\n",
        "\n",
        "def descargar_archivo_a_variable(url:str, filename:str) -> str:\n",
        "  descargar_archivo(url, filename)\n",
        "  with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    return f.read()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tx4odO8dy8Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creamos los Modelos (LLM) enLangchain\n",
        "\n",
        "![image.png](https://drive.google.com/uc?export=download&id=1UbD5tXczZlVJ3xWH6L4eDk4fn-XkfI3V)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Se repiten los casos de clases pasadas para crear los clientes de LLM"
      ],
      "metadata": {
        "id": "qImkB3iUGqT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.messages import HumanMessage, SystemMessage , AIMessage\n",
        "\n",
        "openai_model = init_chat_model(\"gpt-4.1-mini\",      model_provider=\"openai\",        api_key=openai_api_key)\n",
        "gemini_model = init_chat_model(\"gemini-2.0-flash\",  model_provider=\"google_genai\",   api_key=gemini_api_key)\n",
        "\n",
        "print(\"LLMs cargados\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fhhC0SptIHZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vamos a crear un Grafo de Don Quijote\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xrLvVbKj_Enk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "#https://drive.google.com/file/d/1V7lIIJE_rv5XTXfTkvR1Qm82tZeSEKZa/view?usp=drive_link\n",
        "#https://drive.google.com/file/d/1V7lIIJE_rv5XTXfTkvR1Qm82tZeSEKZa/view?usp=drive_link\n",
        "\n",
        "\n",
        "text = descargar_archivo_a_variable(\"https://drive.google.com/uc?export=download&id=1V7lIIJE_rv5XTXfTkvR1Qm82tZeSEKZa\", \"/content/don-quijote-short.txt\")\n",
        "\n",
        "\n",
        "llm_instruction = \"\"\"\n",
        "en el siguiente texto, centrate en buscar relaciones y entidades, como lugares,\n",
        "eventos significativos en los que participan los personajes, tipo de relacion\n",
        "entre los personajes, familiaridad entre, propiedades que tienen, gustos y personalizades,\n",
        "frases o poemas\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "llm_transformer = LLMGraphTransformer(\n",
        "    llm=gemini_model,\n",
        "    #additional_instructions=(llm_instruction)\n",
        "     allowed_nodes=[\"Persona Relevante\",\"Lugar\",\"Batalla\",\"Aventura\",  \"Animal\", \"Objeto\", ],\n",
        "     allowed_relationships=[\"CONOCIDO\", \"AMA\", \"PELEA\", \"IMITA\",  \"FAMILIAR\", \"AMIGO\",\"ESTUVO_EN\", 'OCURRIO_EN', \"DUE√ëO_DE\", \"TRABAJA_PARA\", \"EMPLEADO_DE\", \"PARTICIPO\", \"MISMA_PERSONA\"],\n",
        ")\n",
        "\n",
        "\n",
        "documents = [Document(page_content=text)]\n",
        "\n",
        "print(\"Empieza a analizar el documento\")\n",
        "graph_documents = await llm_transformer.aconvert_to_graph_documents(documents)\n",
        "print(\"Nodes\")\n",
        "for node in graph_documents[0].nodes:\n",
        "    print(node)\n",
        "\n",
        "\n",
        "print(\"Relationships\")\n",
        "for relationship in graph_documents[0].relationships:\n",
        "  print(relationship)\n"
      ],
      "metadata": {
        "id": "LBIJiSMchWxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Una gr√°fica muy bonita del Grafo\n",
        "\n",
        "¬°Qu√© bonito! Podemos dibujar las relaciones.\n"
      ],
      "metadata": {
        "id": "yw-Yuy3pyoQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "graph = graph_documents[0]\n",
        "\n",
        "# Build a NetworkX graph\n",
        "G = nx.DiGraph()\n",
        "for node in graph.nodes:\n",
        "    G.add_node(node.id, label=node.type)\n",
        "for rel in graph.relationships:\n",
        "    G.add_edge(rel.source.id, rel.target.id, label=rel.type)\n",
        "\n",
        "# Draw it\n",
        "pos = nx.spring_layout(G, seed=44, k=1.5, iterations=400)\n",
        "plt.figure(figsize=(16, 12))\n",
        "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=1500, edge_color='gray', font_size=6)\n",
        "edge_labels = nx.get_edge_attributes(G, 'label')\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "plt.title(\"Don quijote Knowledge Graph\", fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sqOGQcUNEDKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problemas de este Grafo\n",
        "\n",
        "Aunque el grafo es muy bonito y bastante impresionante no es muy √∫til porque debemos conocer al detalle lo que hay en cada nodo para hacer una consulta.\n",
        "\n",
        "\n",
        "Necesitamos la m√°gia de los embeddings para poder ubicar un nodo.\n",
        "\n",
        "Para esto usaremos **NEO4J** como base de datos de Grafos.\n",
        "\n",
        "Las credenciales debieron ser asignadas en los primeros nodos.\n"
      ],
      "metadata": {
        "id": "_Xbf-J_qLdZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mMHnbdWtSd8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet neo4j neo4j-graphrag langchain-neo4j langchain-experimental\n",
        "\n",
        "#VALIDEMOS SI TENEMOS LA URL DE NEO4J\n",
        "\n",
        "\n",
        "\n",
        "print(\"Debemos haber asignado NEO4J_URI \",os.environ[\"NEO4J_URI\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "C0TVT7TWawaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **===============================================**\n",
        "##                    RAG   WITH EMBEDDINGS\n",
        "## **===============================================**"
      ],
      "metadata": {
        "id": "sMHEBJv2Jr9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import neo4j\n",
        "\n",
        "\n",
        "neo_auth = (os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
        "\n",
        "neo4j_driver = neo4j.GraphDatabase.driver(os.environ[\"NEO4J_URI\"],auth=neo_auth)\n"
      ],
      "metadata": {
        "id": "BHETrRvtJ8Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#HARRY POTTER\n",
        "\n",
        "##text = descargar_archivo_a_variable(\"https://drive.google.com/uc?export=download&id=1KFENc5Biu0LufLWx1BwhEbKfOmQ3uFFJ\",\"/content/harry_potter.txt\")\n",
        "##print(text)\n",
        "\n",
        "\n",
        "\n",
        "## MUNDIAL SUB-20   https://drive.google.com/file/d/1zuS1YzxHGqw8vqbf-_A53xXsnYAC2uGb/view?usp=drive_link\n",
        "text = descargar_archivo_a_variable(\"https://drive.google.com/uc?export=download&id=1zuS1YzxHGqw8vqbf-_A53xXsnYAC2uGb\",\"/content/sub20.txt\")\n",
        "print(text[:200])\n",
        "print(text[:-200])\n"
      ],
      "metadata": {
        "id": "Yy_MeXxdYKt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Limpiamos la BD\n",
        "################################################################\n",
        "#                          LIMIPIEZA BD\n",
        "################################################################\n",
        "\n",
        "\n",
        "delete_query = \"\"\"\n",
        "MATCH (n)\n",
        "DETACH DELETE n\n",
        "\"\"\"\n",
        "print(\"Execute \",delete_query)\n",
        "neo4j_driver.execute_query(delete_query)"
      ],
      "metadata": {
        "id": "_Ca63wrQ0BXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import neo4j\n",
        "from neo4j_graphrag.llm import OpenAILLM as LLM\n",
        "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings as Embeddings\n",
        "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
        "from neo4j_graphrag.retrievers import VectorRetriever\n",
        "from neo4j_graphrag.generation.graphrag import GraphRAG\n",
        "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from neo4j_graphrag.experimental.components.text_splitters.langchain import LangChainTextSplitterAdapter\n",
        "\n",
        "\n",
        "\n",
        "ex_llm=LLM(\n",
        "   model_name=\"gpt-4o-mini\",\n",
        "   model_params={\n",
        "       \"response_format\": {\"type\": \"json_object\"},\n",
        "       \"temperature\": 0\n",
        "   })\n",
        "\n",
        "embedder = Embeddings()\n",
        "\n",
        "llm_graph_instruction = \"\"\"\n",
        "Eres experto en extraer grafos de conocimiento a partir de textos sobre el Mundial Sub‚Äë20 de F√∫tbol. El texto puede contener alineaciones, formaciones, sedes, √°rbitros, grupos/fases y res√∫menes de partidos (goles, asistencias, tarjetas, sustituciones).\n",
        "\n",
        "Objetivo:\n",
        "- Identifica ENTIDADES (nodos) y RELACIONES (aristas) relevantes para el torneo.\n",
        "- Usa exclusivamente los LABELS y RELATION TYPES permitidos listados abajo.\n",
        "- Devuelve un JSON v√°lido siguiendo estrictamente el esquema indicado.\n",
        "\n",
        "LABELS permitidos (nodos):\n",
        "- Torneo, Partido, Equipo, Seleccion, Club, Jugador, Entrenador, Arbitro,\n",
        "  Estadio, Ciudad, Pais, Grupo, Fase, Premio,\n",
        "  EventoGol, EventoTarjeta, EventoSustitucion\n",
        "\n",
        "RELATION TYPES permitidos (dirigidos):\n",
        "- PARTICIPA_EN (Equipo -> Torneo)\n",
        "- JUGADO_EN (Partido -> Torneo | Fase | Grupo)\n",
        "- LOCAL_EN (Partido -> Equipo)     // equipo local\n",
        "- VISITANTE_EN (Partido -> Equipo) // equipo visitante\n",
        "- SE_JUEGA_EN (Partido -> Estadio)\n",
        "- UBICADO_EN (Estadio -> Ciudad), UBICADO_EN (Ciudad -> Pais)\n",
        "- DIRIGE (Entrenador -> Equipo)\n",
        "- JUEGA_PARA (Jugador -> Seleccion | Equipo)\n",
        "- PERTENECE_A (Jugador -> Club)\n",
        "- NACIONALIDAD (Jugador|Entrenador|Arbitro -> Pais)\n",
        "- ARBITRA (Arbitro -> Partido)\n",
        "- TITULAR_EN (Jugador -> Partido)\n",
        "- SUPLENTE_EN (Jugador -> Partido)\n",
        "- CAPITAN_EN (Jugador -> Partido)\n",
        "- EVENTO_DE (EventoGol|EventoTarjeta|EventoSustitucion -> Partido)\n",
        "- AUTOR (Jugador -> EventoGol)\n",
        "- ASISTE (Jugador -> EventoGol)\n",
        "- TARJETA_A (Jugador -> EventoTarjeta)\n",
        "- SALE_EN (Jugador -> EventoSustitucion)\n",
        "- ENTRA_EN (Jugador -> EventoSustitucion)\n",
        "- GANADOR_DE (Equipo -> Partido)\n",
        "- PERDEDOR_DE (Equipo -> Partido)\n",
        "- EMPATE_EN (Partido -> Torneo) // usar si el partido termin√≥ en empate\n",
        "- GANA_PREMIO (Jugador|Entrenador|Equipo -> Premio)\n",
        "- MIEMBRO_DE (Equipo -> Grupo)\n",
        "- AVANZA_A (Equipo -> Fase)\n",
        "\n",
        "Return result as JSON using the following format:\n",
        "{{\"nodes\": [ {{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {{\"name\": \"name of entity\" }} }}],\n",
        "  \"relationships\": [{{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"details\": \"Description of the relationship\"}} }}] }}\n",
        "\n",
        "\n",
        "Propiedades m√≠nimas sugeridas:\n",
        "- Torneo: name, year\n",
        "- Partido: date (YYYY-MM-DD), time (HH:MM, opcional), fase (opcional), grupo (opcional), score_local (int, opcional), score_visitante (int, opcional)\n",
        "- Equipo/Seleccion: name\n",
        "- Club: name, pais (opcional)\n",
        "- Jugador: name, dorsal (int, opcional), posicion (opcional)\n",
        "- Entrenador/Arbitro: name\n",
        "- Estadio: name, capacidad (int, opcional)\n",
        "- Ciudad/Pais/Grupo/Fase/Premio: name\n",
        "- EventoGol: minuto (int), tipo (\"juego\", \"penal\", \"propia\", opcional)\n",
        "- EventoTarjeta: minuto (int), tipo (\"amarilla\", \"roja\")\n",
        "- EventoSustitucion: minuto (int)\n",
        "\n",
        "Reglas:\n",
        "- No inventes entidades o datos no presentes en el texto.\n",
        "- Reutiliza el mismo nodo si la entidad ya apareci√≥ (evita duplicados).\n",
        "- Usa may√∫sculas sostenidas para RELATION TYPES tal como se listan.\n",
        "- Aseg√∫rate de que cada id de nodo sea √∫nico y que las referencias en relaciones existan.\n",
        "- Normaliza nombres: respeta tildes, usa capitalizaci√≥n natural (e.g., \"Colombia\", \"Espa√±a\").\n",
        "- Minutos y goles deben ser enteros si est√°n presentes.\n",
        "\n",
        "Texto de entrada:\n",
        "{{text}}\n",
        "\"\"\"\n",
        "original_prompt=\"\"\"\n",
        "You are a top-tier algorithm designed for extracting\n",
        "information in structured formats to build a knowledge graph.\n",
        "\n",
        "Extract the entities (nodes) and specify their type from the following text.\n",
        "Also extract the relationships between these nodes.\n",
        "\n",
        "Return result as JSON using the following format:\n",
        "{{\"nodes\": [ {{\"id\": \"0\", \"label\": \"Person\", \"properties\": {{\"name\": \"John\"}} }}],\n",
        "\"relationships\": [{{\"type\": \"KNOWS\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"since\": \"2024-08-01\"}} }}] }}\n",
        "\n",
        "Use only the following node and relationship types (if provided):\n",
        "{schema}\n",
        "\n",
        "Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
        "Do respect the source and target node types for relationship and\n",
        "the relationship direction.\n",
        "\n",
        "Make sure you adhere to the following rules to produce valid JSON objects:\n",
        "‚Ä¢‚Å†  ‚Å†Do not return any additional information other than the JSON in it.\n",
        "‚Ä¢‚Å†  ‚Å†Omit any backticks around the JSON - simply output the JSON on its own.\n",
        "‚Ä¢‚Å†  ‚Å†The JSON object must not wrapped into a list - it is its own JSON object.\n",
        "‚Ä¢‚Å†  ‚Å†Property names must be enclosed in double quotes\n",
        "\n",
        "Examples:\n",
        "{examples}\n",
        "\n",
        "Input text:\n",
        "\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "# Relationship types (directed)\n",
        "rel_types = [\n",
        "    \"PARTICIPA_EN\", \"JUGADO_EN\", \"MIEMBRO_DE\", \"AVANZA_A\",\n",
        "    \"SE_JUEGA_EN\", \"UBICADO_EN\",\n",
        "    \"DIRIGE\", \"JUEGA_PARA\", \"PERTENECE_A\", \"NACIONALIDAD\",\n",
        "    \"LOCAL_EN\", \"VISITANTE_EN\", \"ARBITRA\",\n",
        "    \"TITULAR_EN\", \"SUPLENTE_EN\", \"CAPITAN_EN\",\n",
        "    \"EVENTO_DE\", \"AUTOR\", \"ASISTE\", \"TARJETA_A\",\n",
        "    \"SALE_EN\", \"ENTRA_EN\",\n",
        "    \"GANADOR_DE\", \"PERDEDOR_DE\", \"EMPATE_EN\", \"GANA_PREMIO\"\n",
        "]\n",
        "\n",
        "basic_node_labels = [\n",
        "    \"Torneo\", \"Partido\", \"Equipo\", \"Seleccion\", \"Club\",\n",
        "    \"Jugador\", \"Entrenador\", \"Arbitro\",\n",
        "    \"Estadio\", \"Ciudad\", \"Pais\",\n",
        "    \"Grupo\", \"Fase\", \"Premio\",\n",
        "    \"EventoGol\", \"EventoTarjeta\", \"EventoSustitucion\"\n",
        "]\n",
        "node_labels = basic_node_labels\n",
        "rct_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=700,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
        ")\n",
        "text_splitter = LangChainTextSplitterAdapter(rct_splitter)\n",
        "\n",
        "# 1. Build KG and Store in Neo4j Database\n",
        "kg_builder_pdf = SimpleKGPipeline(\n",
        "   llm=ex_llm,\n",
        "   driver=neo4j_driver,\n",
        "   text_splitter=FixedSizeSplitter(chunk_size=500, chunk_overlap=100),\n",
        "   embedder=embedder,\n",
        "   entities=node_labels,\n",
        "   relations=rel_types,\n",
        "   prompt_template=original_prompt,\n",
        "   from_pdf=False,\n",
        "   perform_entity_resolution=True\n",
        ")\n",
        "\n",
        "await kg_builder_pdf.run_async(text=text)\n"
      ],
      "metadata": {
        "id": "O6TBcoXDNHs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from neo4j_graphrag.experimental.components.resolver import (\n",
        "    #SinglePropertyExactMatchResolver,\n",
        "     SpaCySemanticMatchResolver,\n",
        "    # FuzzyMatchResolver,\n",
        ")\n",
        "#resolver = SinglePropertyExactMatchResolver(neo4j_driver)  # exact match resolver\n",
        "resolver = SpaCySemanticMatchResolver(neo4j_driver)  # semantic match with spaCy\n",
        "# resolver = FuzzyMatchResolver(driver)  # fuzzy match with RapidFuzz\n",
        "res = await resolver.run()\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "X8DUxSsRmEW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "#Merge nodes\n",
        "with neo4j_driver.session() as session:\n",
        "    session.run(\"\"\"\n",
        "    MATCH (n:Entity)\n",
        "    WITH n.name AS name, collect(n) AS nodes\n",
        "    WHERE size(nodes) > 1\n",
        "    CALL apoc.refactor.mergeNodes(nodes, {properties:\"combine\"})\n",
        "    YIELD node\n",
        "    RETURN node\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "qFKYEvtCdS3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DEBEMOS CREAR UN VECTOR INDEX PARA PODER CONSULTAR\n",
        "import neo4j\n",
        "from neo4j_graphrag.indexes import create_vector_index\n",
        "\n",
        "create_vector_index(neo4j_driver, name=\"text_embeddings\", label=\"Chunk\",embedding_property=\"embedding\", dimensions=1536, similarity_fn=\"cosine\")"
      ],
      "metadata": {
        "id": "5R2bQ74oeXTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "##   CONSULTA  VectorRetriever\n",
        "##\n",
        "\n",
        "\n",
        "import neo4j\n",
        "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings as Embeddings\n",
        "from neo4j_graphrag.retrievers import VectorRetriever,HybridRetriever\n",
        "\n",
        "from neo4j_graphrag.generation.graphrag import GraphRAG\n",
        "from neo4j_graphrag.llm import OpenAILLM as LLM\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import json\n",
        "import os\n",
        "\n",
        "pregunta = \"Cual jugador del Cruzeiro le hizo gol a Espa√±a\"\n",
        "\n",
        "\n",
        "\n",
        "# 2. KG Retriever\n",
        "vector_retriever = VectorRetriever(neo4j_driver,index_name=\"text_embeddings\",embedder=embedder)\n",
        "vector_resp  = vector_retriever.get_search_results(query_text=pregunta, top_k=5)\n",
        "\n",
        "print(\"VECTOR RETRIEVER\")\n",
        "for record  in vector_resp.records:\n",
        "  print(\"===========\\n\" + json.dumps(record, indent=4))\n",
        "\n",
        "print(\"====================================================\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Cgc2Sw6Jq-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import neo4j\n",
        "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings as Embeddings\n",
        "from neo4j_graphrag.retrievers import VectorRetriever,HybridRetriever,VectorCypherRetriever\n",
        "\n",
        "from neo4j_graphrag.generation.graphrag import GraphRAG\n",
        "from neo4j_graphrag.llm import OpenAILLM as LLM\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "retrieval_query = \"\"\"MATCH (n)-[:FROM_CHUNK]->(node)\n",
        "RETURN collect(n) AS sources\n",
        "\"\"\"\n",
        "\n",
        "retrieval_query = \"\"\"\n",
        "\n",
        "\n",
        "WITH node AS chunk\n",
        "\n",
        "// Buscar nodos _Entity_ conectados a este chunk\n",
        "OPTIONAL MATCH (e1:_Entity_)-[:FROM_CHUNK]->(chunk)\n",
        "\n",
        "// Obtener relaciones entre entidades\n",
        "OPTIONAL MATCH (e1)-[r]-(e2:_Entity_)\n",
        "WHERE NOT type(r) IN ['FROM_CHUNK', 'FROM_DOCUMENT', 'NEXT_CHUNK']\n",
        "\n",
        "// Obtener los chunks de origen de las entidades relacionadas\n",
        "OPTIONAL MATCH (e2)-[:FROM_CHUNK]->(c2:Chunk)\n",
        "\n",
        "RETURN\n",
        "    chunk,\n",
        "    collect(DISTINCT e1) AS entities_1,\n",
        "    collect(DISTINCT e2) AS entities_2,\n",
        "    collect(DISTINCT r) AS relationships,\n",
        "    collect(DISTINCT c2) AS related_chunks\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "retrieval_query = \"\"\"\n",
        "WITH node AS chunk\n",
        "\n",
        "// Buscar nodos _Entity_ conectados a este chunk\n",
        "OPTIONAL MATCH (e1:_Entity_)-[:FROM_CHUNK]->(chunk)\n",
        "\n",
        "// Obtener relaciones entre entidades\n",
        "OPTIONAL MATCH (e1)-[r]-(e2:_Entity_)\n",
        "WHERE NOT type(r) IN ['FROM_CHUNK', 'FROM_DOCUMENT', 'NEXT_CHUNK']\n",
        "\n",
        "// Obtener los chunks de origen de las entidades relacionadas\n",
        "OPTIONAL MATCH (e2)-[:FROM_CHUNK]->(c2:Chunk)\n",
        "\n",
        "// Retornar sin incluir la propiedad 'embedding'\n",
        "RETURN\n",
        "    chunk { .* , embedding: null } AS chunk,\n",
        "    [e IN collect(DISTINCT e1) | e { .* , embedding: null }] AS entities_1,\n",
        "    [e IN collect(DISTINCT e2) | e { .* , embedding: null }] AS entities_2,\n",
        "    collect(DISTINCT r) AS relationships,\n",
        "    [c IN collect(DISTINCT c2) | c { .* , embedding: null }] AS related_chunks\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "retrieval_query = \"\"\"\n",
        "CALL db.index.vector.queryNodes('text_embeddings', $top_k, $query_vector)\n",
        "YIELD node AS chunk, score AS similarity_score\n",
        "MATCH (chunk)-[r]->(m)\n",
        "RETURN chunk, r, m, similarity_score\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "retrieval_query = \"MATCH (node) RETURN node\"\n",
        "\n",
        "retrieval_query_c2 = \"\"\"\n",
        "CALL db.index.vector.queryNodes('text_embeddings', $top_k, $query_vector)\n",
        "YIELD node AS chunk, score AS similarity_score\n",
        "MATCH (chunk)-[r]->(child)-[rr]->(child2)\n",
        "RETURN\n",
        "  similarity_score,\n",
        "  r,\n",
        "  rr,\n",
        "  apoc.map.removeKey(properties(chunk), 'embedding') AS chunk,\n",
        "  apoc.map.removeKey(properties(child), 'embedding') AS child,\n",
        "  apoc.map.removeKey(properties(child2), 'embedding') AS child2\n",
        "ORDER BY similarity_score DESC\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "retrieval_query_u = \"\"\"\n",
        "CALL db.index.vector.queryNodes('text_embeddings', $top_k, $query_vector)\n",
        "YIELD node AS chunk, score AS similarity_score\n",
        "MATCH (chunk)\n",
        "RETURN DISTINCT\n",
        "  similarity_score,\n",
        "  apoc.map.removeKey(properties(chunk), 'embedding') AS chunk\n",
        "UNION\n",
        "CALL db.index.vector.queryNodes('text_embeddings', $top_k, $query_vector)\n",
        "YIELD node AS chunk, score AS similarity_score\n",
        "MATCH (chunk)-[r]->(child)-[rr]->(child2)\n",
        "RETURN DISTINCT\n",
        "  similarity_score,\n",
        "  apoc.map.removeKey(properties(child), 'embedding') AS chunk\n",
        "ORDER BY similarity_score DESC\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "re_hops =\"\"\"\n",
        "//1) Go out up to N hops in the entity graph and get relationships\n",
        "WITH node AS chunk\n",
        "MATCH (chunk)<-[:FROM_CHUNK]-()-[relList:!FROM_CHUNK]-{1,4}()\n",
        "UNWIND relList AS rel\n",
        "\n",
        "//2) collect relationships and text chunks\n",
        "WITH collect(DISTINCT chunk) AS chunks,\n",
        " collect(DISTINCT rel) AS rels\n",
        "\n",
        "//3) format and return context\n",
        "RETURN '=== text ===n' + apoc.text.join([c in chunks | c.text], 'n---n') + 'nn=== kg_rels ===n' +\n",
        " apoc.text.join([r in rels | startNode(r).name + ' - ' + type(r) + '(' + coalesce(r.details, '') + ')' +  ' -> ' + endNode(r).name ], 'n---n') AS info\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "pregunta = \"en que club juega el arquero a quien le sacaron tarjeta amarilla por juego peligroso\"\n",
        "\n",
        "vector_cypher_retriever = VectorCypherRetriever(neo4j_driver, \"text_embeddings\", re_hops, embedder)\n",
        "vc_resp = vector_cypher_retriever.get_search_results(query_text=pregunta, top_k=5)\n",
        "\n",
        "print(\"VectorCypherRetriever \",pregunta)\n",
        "print(vc_resp)\n",
        "print(\"------------\")\n",
        "for record  in vc_resp.records:\n",
        "  print(type(record))\n",
        "  print(record)\n",
        "  #print(\"===========\\n\" + json.dumps(record, indent=4))\n",
        "\n",
        "print(\"====================================================\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-fNViHl-C-X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = LLM(model_name=\"gpt-5-nano\")\n",
        "rag = GraphRAG(llm=llm, retriever=vector_cypher_retriever)\n",
        "\n",
        "pregunta = \"en que club juega el arquero a quien le sacaron tarjeta amarilla por juego peligroso o su nacionalidad\"\n",
        "print(\"PREGUNTA\",pregunta)\n",
        "resp = rag.search(pregunta)\n",
        "print(resp)\n"
      ],
      "metadata": {
        "id": "MX6VV3Afns6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j_graphrag.generation import RagTemplate, GraphRAG\n",
        "\n",
        "prompt_template = RagTemplate(\n",
        "    template=\"Answer the question using only context {context} and examples\",\n",
        "    expected_inputs=[\"context\"]\n",
        ")\n",
        "\n",
        "llm = LLM(model_name=\"gpt-4o-mini\")\n",
        "rag = GraphRAG(retriever=vector_cypher_retriever, llm=llm, prompt_template=prompt_template)\n",
        "\n",
        "pregunta = \"En cual equipo (club) juega quien  hizo gol el ultimo gol de la final\"\n",
        "print(\"PREGUNTA\",pregunta)\n",
        "resp = rag.search(pregunta)\n",
        "print(resp)"
      ],
      "metadata": {
        "id": "x84sC0GqZagc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def parse_kg_edges_from_info(info: str):\n",
        "    sep = \"\\n\\n=== kg_rels ===\\n\"\n",
        "    pos = info.find(sep)\n",
        "    if pos == -1:\n",
        "        return [], \"\"\n",
        "    text_part = info[:pos]\n",
        "    kg_part = info[pos + len(sep):]\n",
        "    lines = [ln.strip() for ln in kg_part.split(\"\\n\") if ln.strip() and ln.strip() != '---']\n",
        "    edges = []\n",
        "    for ln in lines:\n",
        "        # expected: <start> - <TYPE> -> <end>\n",
        "        # split on ' - ' then ' -> '\n",
        "        if ' - ' in ln and ' -> ' in ln:\n",
        "            left, _, rest = ln.partition(' - ')\n",
        "            type_, _, right = rest.partition(' -> ')\n",
        "            start = left.strip()\n",
        "            end = right.strip()\n",
        "            edges.append((start, type_.strip(), end))\n",
        "    return edges, text_part\n",
        "\n",
        "\n",
        "def visualize_vc_subgraph(vc, query_text: str, top_k: int = 1):\n",
        "    res = vc.get_search_results(query_text=query_text, top_k=top_k)\n",
        "    info = res.records[0]['info']\n",
        "    edges, text_part = parse_kg_edges_from_info(info)\n",
        "\n",
        "    print(\"# Text Chunk Context (truncated):\")\n",
        "    print(text_part[:600])\n",
        "\n",
        "    if not edges:\n",
        "        print(\"\\n(No KG relationships parsed. Try one-hop retriever or adjust query.)\")\n",
        "        return\n",
        "\n",
        "    # Build graph\n",
        "    G = nx.DiGraph()\n",
        "    for s, t, e in edges:\n",
        "        G.add_node(s)\n",
        "        G.add_node(e)\n",
        "        G.add_edge(s, e, label=t)\n",
        "\n",
        "    # Draw\n",
        "    pos = nx.spring_layout(G, seed=42, k=1.5, iterations=200)\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    nx.draw(G, pos, with_labels=True, node_color='lightyellow', node_size=1800, edge_color='gray', font_size=10)\n",
        "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=9)\n",
        "    plt.title(\"VC Subgraph (parsed from kg_rels)\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "simple_multihop = \"\"\"\n",
        "WITH node AS chunk\n",
        "// Just get entities that have relationships (ignoring how they connect to chunk)\n",
        "MATCH (e1)-[r]-(e2)\n",
        "WHERE NOT (e1:Chunk OR e1:Document OR e1:_KGBuilder_)\n",
        "  AND NOT (e2:Chunk OR e2:Document OR e2:_KGBuilder_)\n",
        "  AND NOT type(r) IN ['NEXT_CHUNK', 'FROM_DOCUMENT', 'FROM_CHUNK']\n",
        "WITH chunk, collect(DISTINCT r) AS rels LIMIT 1\n",
        "RETURN '=== text ===\\\\n' + chunk.text + '\\\\n\\\\n=== kg_rels ===\\\\n' +\n",
        "       apoc.text.join([r IN rels |\n",
        "            coalesce(startNode(r).name, startNode(r).id, elementId(startNode(r))) +\n",
        "            ' - ' + type(r) + ' -> ' +\n",
        "            coalesce(endNode(r).name, endNode(r).id, elementId(endNode(r)))\n",
        "       ], '\\\\n---\\\\n') AS info\n",
        "\"\"\"\n",
        "\n",
        "vc_simple = VectorCypherRetriever(\n",
        "    neo4j_driver,\n",
        "    index_name=\"text_embeddings\",\n",
        "    embedder=embedder,\n",
        "    retrieval_query=simple_multihop\n",
        ")\n",
        "\n",
        "try:\n",
        "    visualize_vc_subgraph(vc_simple, query_text=\"seleccion colombia\", top_k=1)\n",
        "except Exception as e:\n",
        "    print(\"Simple multi-hop error:\", e)"
      ],
      "metadata": {
        "id": "5NwQbqmZlk4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "query = \"Cuales son los jugadores con las goles y que para que equipos juegan los que mas los asisten\"\n",
        "vector_results = vector_retriever.get_search_results(query_text=query, top_k=3)\n",
        "cypher_results = vector_cypher_retriever.get_search_results(query_text=query, top_k=3)\n",
        "\n",
        "def clean_results(results):\n",
        "    # Remove query_vector from results metadata\n",
        "    if hasattr(results, 'metadata') and 'query_vector' in results.metadata:\n",
        "        del results.metadata['query_vector']\n",
        "\n",
        "    # Also clean individual records if needed\n",
        "    if hasattr(results, 'records'):\n",
        "        for record in results.records:\n",
        "            # Check metadata\n",
        "            if hasattr(record, 'metadata') and 'query_vector' in record.metadata:\n",
        "                del record.metadata['query_vector']\n",
        "\n",
        "    return results\n",
        "\n",
        "vector_results = clean_results(vector_results)\n",
        "cypher_results = clean_results(cypher_results)\n",
        "\n",
        "print(\"VECTOR RESULTS:\")\n",
        "print(vector_results)\n",
        "print(\"\\nCYPHER RESULTS:\")\n",
        "print(cypher_results)"
      ],
      "metadata": {
        "id": "bxlkch9HsMfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_results(query, results):\n",
        "    system_prompt = f\"\"\"Eres un experto en an√°lisis de informacion deportiva.\n",
        "Has recibido resultados de un sistema de recuperaci√≥n de informaci√≥n.\n",
        "\n",
        "Tu tarea es:\n",
        "1. Analizar los resultados de recuperaci√≥n proporcionados\n",
        "2. Responder la pregunta del usuario de manera completa y precisa\n",
        "3. Proporcionar informaci√≥n relevante basada en el contexto recuperado\n",
        "\n",
        "Responde en espa√±ol de manera clara y estructurada.\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "PREGUNTA DEL USUARIO: {query}\n",
        "\n",
        "Retrieval Results: {str(results)}\n",
        "\n",
        "Por favor, analiza los resultados de recuperaci√≥n y responde la pregunta del usuario de manera completa.\n",
        "\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=system_prompt),\n",
        "        HumanMessage(content=user_prompt)\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = gemini_model.invoke(messages)\n",
        "        return response.content\n",
        "    except Exception as e:\n",
        "        return f\"Error al procesar con Gemini: {e}\"\n",
        "\n",
        "print(\"\\nRespuesta Con Vectores\")\n",
        "print(\"=\"*80)\n",
        "response = process_results(query, vector_results)\n",
        "print(response)\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nRespuesta Con Vectores + Nodes\")\n",
        "print(\"=\"*80)\n",
        "response = process_results(query, cypher_results)\n",
        "print(response)\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "H95yJZi0sNs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2PCiixZtj7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}